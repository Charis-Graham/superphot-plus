{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1011fb76-c186-45a1-aaf0-f862cf2a943f",
   "metadata": {},
   "source": [
    "# Full Train Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e576c-1661-4fba-9a2c-f5d7e5311056",
   "metadata": {},
   "source": [
    "Run when you need to train a new classifier from scratch. Will regenerate transient data, refit all samples, and retrain the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d4adc-97f4-4646-b752-e29e7b2d5f03",
   "metadata": {},
   "source": [
    "## Step 0: Update configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b5c23-342c-40f8-912b-67c3a349503e",
   "metadata": {},
   "source": [
    "In the same folder as this notebook, there is a $\\texttt{config.yaml}$ file, which contains all filepaths and configuration options for the training workflow. Please update this now!\n",
    "\n",
    "The most important filepath arguments are:\n",
    "* $\\texttt{create-dirs}$: Probably keep set to True. Create any data subdirectories that are missing.\n",
    "* $\\texttt{data-dir}$: This is where all generated data is stored. Set to the root directory for all outputs.\n",
    "* $\\texttt{relative-dirs}$: If true, all data for each step is stored within subdirectories of data_dir.\n",
    "* $\\texttt{transient-data-fn}$: This is where all transient data is stored as a TransientGroup. Technically a directory but loaded as a single file. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{sampler-results-fn}$: Where light curve fits are stored. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{figs-dir}$: Where all figures are stored (only generated if $\\texttt{plot}$ is set to True). If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{models-dir}$: Where all classification models are stored. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "\n",
    "The most important sampling and classifier arguments are:\n",
    "* $\\texttt{sampler}$: Set to either dynesty or svi (all lowercase). SVI is faster but forces the posterior into a multivariate Gaussian.\n",
    "* $\\texttt{model-type}$: Set to either LightGBM (recommended) or MLP.\n",
    "* $\\texttt{use-redshift-features}$: If True, includes peak absolute magnitude and redshift as training features.\n",
    "* $\\texttt{fits-per-majority}$: Oversamples such that the majority class has this many samples fed into the classifier. Minority classes will correspond to more input samples per event. Defaults to 5.\n",
    "* $\\texttt{target-label}$: For binary classification - this is the positive label. Set to None for multiclass classification.\n",
    "* $\\texttt{n-folds}$: Number of K-folds. I usually set to 10.\n",
    "* $\\texttt{num-epochs}$: Number of estimators for LightGBM or number of training epochs for MLP.\n",
    "* $\\texttt{n-parallel}$: Number of threads to parallelize data import + sampling over.\n",
    "* $\\texttt{random-seed}$: For reproducibility.\n",
    "\n",
    "If you want to use hierarchical classification with the MLP, you need to also manually fill in the following:\n",
    "* $\\texttt{hierarchy}$: Set to True if you want to use the weighted hierarchical loss function (WHXE). Otherwise, make sure this is set to False.\n",
    "* $\\texttt{class-weights}$: Manually import these values using the class_weights.ipynb notebook to calculate the relevant class weights for the (WHXE). If you are not using this, set it to None.\n",
    "* $\\texttt{graph}$: This is a dictionary of properties of the taxonomic graph. Set each element to null if not using the WHXE.\n",
    "    * $\\texttt{edges}$: A list of 2-element lists containing the edges in the taxonomic graph in use. If not using WHXE, set to None.\n",
    "    * $\\texttt{height}$: The height you want the classifier to go to in terms of the taxonomic tree. Set to None if not using WHXE.\n",
    "    * $\\texttt{root}$: The root node of the tree as a string. This is set to None if not using WHXE.\n",
    "    * $\\texttt{vertices}$: A list of all of the vertices within the tree, including those that are not labels within the dataset. Set to None if not using WHXE. \n",
    "    * $\\texttt{ignored-leaves}$: A list of the leaf vertices within the tree that do not have any counts for them within class_weights or we otherwise want to ignore. Set to None if not using WHXE.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef53e57-bef4-4755-94b1-477a7d6620ec",
   "metadata": {},
   "source": [
    "## Step 1: Generate new TransientSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06baa7f-5374-448d-acdb-8bbc5404a387",
   "metadata": {},
   "source": [
    "Here we will import data from TNS + ALeRCE and generate a new TransientSet, from a list of event names. Names can be from TNS or ZTF.\n",
    "\n",
    "The below code block will retrieve all spectroscopically classified TNS transients. Feel free to change to your own list of names or import script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79328b-94f8-4bd6-8cd7-885799db4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from snapi.query_agents import TNSQueryAgent\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "print(p)\n",
    "#SAVE_DIR = os.path.join(p, \"data\", \"tutorial\") # Use this line if you want to use tutorial data.\n",
    "SAVE_DIR = os.path.join(p, \"docs\", \"notebooks\", \"whxe_notebooks\", \"data\")\n",
    "print(SAVE_DIR)\n",
    "\n",
    "tns_agent = TNSQueryAgent(db_path=SAVE_DIR)\n",
    "#tns_agent.update_local_database() # IMPORTANT: run this line if first time using SNAPI or if you want to reimport TNS csv\n",
    "all_names = tns_agent.retrieve_all_names() # only spectroscopically classified\n",
    "all_names = [x for x in all_names if int(x[:4]) > 2018] # because pre-2019 templates are pretty bad\n",
    "print(len(all_names), all_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc3dda-d71f-4da0-9a68-59526d0916ad",
   "metadata": {},
   "source": [
    "The following script will import data for all provided names and generate a TransientGroup object. Will run in parallel across n_cores threads.\n",
    "\n",
    "For the entire TNS dataset (~16000 events), this takes ~30 minutes on 8 parallel cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First augments the config file to save to your data folder path!\n",
    "# Feel free to change to any path you want\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "config.update(data_dir=SAVE_DIR)\n",
    "config.write_to_file('config.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f8548-4c29-44aa-b14a-a9b1432e264b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "from superphot_plus.data_generation import import_all_names\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "save_dir = config.transient_data_fn\n",
    "\n",
    "# import data for all_names from query agents \n",
    "# QUALITY CUTS HAPPEN HERE\n",
    "import_all_names(\n",
    "    all_names, save_dir,\n",
    "    checkpoint_freq=100,\n",
    "    n_cores=config.n_parallel,\n",
    "    overwrite=False,\n",
    "    skipped_names_fn = os.path.join(config.data_dir, \"skipped_names.txt\")\n",
    ") # set overwrite=False to continue from where left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332fc7c-1f2f-42ce-a9c2-38c8dbc9db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the TransientGroup we created!\n",
    "from snapi import TransientGroup\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "\n",
    "print(len(transient_group.metadata))\n",
    "print(transient_group.metadata.head())\n",
    "print(transient_group.metadata.groupby('spec_class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb3a4d-810c-47df-9a68-9c94070ef085",
   "metadata": {},
   "source": [
    "Finally, before fitting, we want to phase and normalize all the photometry. This is because our samplers expect light curves to already be phased and normalized before fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b45fd",
   "metadata": {},
   "source": [
    "---- REMOVE LATER ----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c6f5c",
   "metadata": {},
   "source": [
    "### STEP 1.5: Hierarchical Counts + Class Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e462753",
   "metadata": {},
   "source": [
    "If we are using WHXE in an MLP, we need generate a taxonomy to be used in our Weighted Hierachical Cross Entropy Loss function.\n",
    "\n",
    "We want to use the counts of items following the quality cuts as that is what our model is training on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bfb94b",
   "metadata": {},
   "source": [
    "##### Substep 1: We want to load in the quality cut data as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "import pandas as pd\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "if config.use_hierarchy:\n",
    "    df = transient_group.metadata\n",
    "    df.to_csv('./whxe_notebooks/data/quality_cut_tns_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bb569",
   "metadata": {},
   "source": [
    "##### Substep 2: Adjust Weights, Labels, and Tree\n",
    "\n",
    "Here we need to adjust a few things:\n",
    "\n",
    "1. Update the weight dictionary to be based on the data following the quality cuts in **import_all_names** above. \n",
    "2. Adjust the tree/taxonomy the user inputted above to desired **height** given in **config.yaml** and develop an updated mapping schema based on the **mapping** schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e545a4",
   "metadata": {},
   "source": [
    "##### Task 2.1 Update Weight Dictionary\n",
    "\n",
    "If you hadn't originally, go back to the **class_weights.ipynb** file and change the loaded in CSV file into the CSV of the file following quality cuts. Rerun this and update the config.yaml file as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "from superphot_plus.model.taxonomy import Taxonomy\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "print(config.class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52058ac",
   "metadata": {},
   "source": [
    "##### Task 2.2 Adjust the Tree & Mapping\n",
    "\n",
    "We need to define the taxonomy class variable to be used as our tree for processing as well as adjust the tree (and relevant values) to the desired height. This all happens in the backend when defining **taxonomy**. We also want to define the mapping schema for values down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "from superphot_plus.model.taxonomy import Taxonomy\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "if config.use_hierarchy:\n",
    "    taxonomy = Taxonomy(config)\n",
    "    print(taxonomy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_hierarchy:    \n",
    "    taxonomy.draw_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0421e9",
   "metadata": {},
   "source": [
    "---- REMOVE LATER ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e95c4-e3aa-4978-8a45-b5e248ea6310",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2 (Option 1): Fit all transients using SVI (faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2e7f9-a9bd-4c61-80ab-9c88f2252c90",
   "metadata": {},
   "source": [
    "Here, we choose to fit our transients using stochastic variational inference (SVI). If using this option, make sure sampler='superphot_svi' in the config.yaml file. This option is faster but assumes Gaussianity of the posterior space, which can be limiting for certain light curve fits.\n",
    "\n",
    "For all 7202 TNS transients passing quality cuts, this takes ~30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06532f86-feb2-45da-ab33-49966d1f14d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snapi.scripts import fit_transient_group\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "from superphot_plus.samplers.numpyro_sampler import SVISampler\n",
    "from superphot_plus.priors import generate_priors, SuperphotPrior\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "SAVE_DIR = os.path.join(p, \"data\", \"tutorial\")\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "#priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "priors = SuperphotPrior.load(SAVE_DIR + \"/\" + \"global_priors_hier_svi\")\n",
    "svi_sampler = SVISampler(\n",
    "    priors=priors,\n",
    "    num_iter=10_000,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "print(\"Transient group loaded\")\n",
    "\n",
    "result = fit_transient_group(\n",
    "    transient_group,\n",
    "    sampler = svi_sampler,\n",
    "    parallelize=True,\n",
    "    n_parallel=config.n_parallel,\n",
    "    checkpoint_fn = os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    "    checkpoint_freq = 512,\n",
    "    pad=True,\n",
    "    overwrite=True # set to False to continue where left off\n",
    ")\n",
    "SamplerResultGroup(result).save(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9646f8-e84d-4ebb-97e2-9896fbed67a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check plot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import TransientGroup, SamplerResultGroup, Formatter\n",
    "from superphot_plus.samplers.numpyro_sampler import SVISampler\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "svi_sampler = SVISampler(\n",
    "    priors=priors,\n",
    "    num_iter=10_000,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "print(len(sampler_results), sampler_results.metadata.tail())\n",
    "names = sampler_results.metadata.index\n",
    "\n",
    "formatter = Formatter()\n",
    "for n in names[-5:]:\n",
    "    t = transient_group[n] # can index like dictionary\n",
    "    sr = sampler_results[n]\n",
    "    svi_sampler.load_result(sr)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    svi_sampler.plot_fit(\n",
    "        ax,\n",
    "        photometry = t.photometry,\n",
    "        formatter = formatter,\n",
    "    )\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    t.photometry.plot(\n",
    "        ax,\n",
    "        mags=False,\n",
    "        formatter=formatter\n",
    "    )\n",
    "    formatter.make_plot_pretty(ax)\n",
    "    formatter.add_legend(ax)\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4ce7d-b8ad-402f-8d3a-84fc21fb9b85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2 (Option 2): Fit light curves using dynesty (slower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a2595-fc7d-46ab-bd7f-d2d753e94c3f",
   "metadata": {},
   "source": [
    "Here, we fit our transient photometry using the dynesty nested sampler. This is slower but does not assume Gaussianity of the posterior space, so can better capture degeneracies between parameters. If you use this, make sure to set sampler=superphot_dynesty in the config.yaml file.\n",
    "\n",
    "Runtime for 7202 TNS samples: ~200 minutes (3.5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c3810-fd87-4257-9682-ba600fe2d0b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snapi.scripts import fit_transient_group\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "from superphot_plus.samplers.dynesty_sampler import DynestySampler\n",
    "from superphot_plus.priors import generate_priors, SuperphotPrior\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "SAVE_DIR = os.path.join(p, \"data\", \"tutorial\")\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "#priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "priors = SuperphotPrior.load(SAVE_DIR + \"/\" + \"global_priors_hier_svi\")\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "print(\"Transient group loaded\")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "\n",
    "dynesty_sampler = DynestySampler(\n",
    "    priors=priors,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "result = fit_transient_group(\n",
    "    transient_group,\n",
    "    sampler = dynesty_sampler,\n",
    "    parallelize=True,\n",
    "    n_parallel=config.n_parallel,\n",
    "    checkpoint_fn = os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    "    checkpoint_freq = 128,\n",
    "    pad=False,\n",
    "    overwrite=True, # False to continue from checkpoint\n",
    ")\n",
    "SamplerResultGroup(result).save(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e8afc-964a-4cfd-86e4-818f14eb874a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check plot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import TransientGroup, SamplerResultGroup, Formatter\n",
    "from superphot_plus.samplers.dynesty_sampler import DynestySampler\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "\n",
    "svi_sampler = DynestySampler(\n",
    "    priors=priors,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "names = sampler_results.metadata.index\n",
    "\n",
    "formatter = Formatter()\n",
    "for n in names[-5:]: # neweet \n",
    "    t = transient_group[n] # can index like dictionary\n",
    "    sr = sampler_results[n]\n",
    "    svi_sampler.load_result(sr)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    svi_sampler.plot_fit(\n",
    "        ax,\n",
    "        photometry = t.photometry,\n",
    "        formatter = formatter,\n",
    "    )\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    t.photometry.plot(\n",
    "        ax,\n",
    "        mags=False,\n",
    "        formatter=formatter\n",
    "    )\n",
    "    formatter.make_plot_pretty(ax)\n",
    "    formatter.add_legend(ax)\n",
    "\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3bf32-e38c-4bf9-874f-c77a9bd19610",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2.5: Convert SamplerResultGroup posteriors back to uncorrelated Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c543bc2-98a5-403f-9bde-d487bb9d02cf",
   "metadata": {},
   "source": [
    "When sampling, the posteriors are saved as the inputs to our flux model. The Gaussian priors, however, were converted to log-Gaussians and multiplied by base parameters where necessary before being fed into the model function. Therefore, we must revert these log-Gaussian and relative parameters back to their original uncorrelated Gaussian draws before using as classifier inputs. We do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dacf611-9d09-4e09-9999-95c5975675e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: only run once!\n",
    "import os\n",
    "from snapi import SamplerResultGroup\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "new_sr = []\n",
    "for i, sr in enumerate(sampler_results):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Converted {i} out of {len(sampler_results)} fits\")\n",
    "    sr.fit_parameters = priors.reverse_transform(sr.fit_parameters)\n",
    "    new_sr.append(sr)\n",
    "    \n",
    "new_sampler_results = SamplerResultGroup(new_sr)\n",
    "new_sampler_results.save(config.sampler_results_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi import SamplerResultGroup\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "import os\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "srg = SamplerResultGroup.load(config.sampler_results_fn)\n",
    "metadata = srg.metadata\n",
    "metadata.to_csv(os.path.join(config.data_dir, \"all_samples.csv\"))\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128b82d-9162-47c1-adf9-4fe3a65a305b",
   "metadata": {},
   "source": [
    "## Step 3: Train + evaluate classifier from sampling posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb48bb5-24ed-4017-8b29-fca16da4e049",
   "metadata": {},
   "source": [
    "Here we train a classifier with our uncorrelated posterior features. This script will automatically split the data into K-folds, oversample the training and validation sets to even out minority classes, and train either LightGBMs (recommended) or MLPs. If plot is True, metric plots and confusion matrices will also be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076c371-e919-4dc8-807c-b2aa585776dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus import SuperphotConfig, SuperphotTrainer\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "# remove A_ZTF_r and t_0_ZTF_r from params used in classification - see paper for details\n",
    "metadata = pd.read_csv(os.path.join(config.data_dir, \"all_samples.csv\"), index_col = 0)\n",
    "keep_cols = metadata.drop(\n",
    "    columns=['A_ZTF_r_median', 't_0_ZTF_r_median', 'score_median', 'sampler']\n",
    ").columns\n",
    "config.input_features = [c.replace(\"_median\", \"\") for c in keep_cols]\n",
    "print(config.input_features)\n",
    "\n",
    "# train classifier\n",
    "trainer = SuperphotTrainer(config)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90d6f4",
   "metadata": {},
   "source": [
    "Finally, we train a version of the classifier without a test set (aka we use the entire dataset in training or validation). This is what we'll be using to classify a new, disparate dataset.\n",
    "\n",
    "In addition to the classic full-phase classifier, we train a classifier that only uses early-phase features (excludes plateau durations and fall timescales). This is more effective at classifying partial supernova light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc790c91-898a-4e3f-b94c-c96377e448af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus import SuperphotConfig, SuperphotTrainer\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "srg = SamplerResultGroup.load(config.sampler_results_fn)\n",
    "\n",
    "trainer = SuperphotTrainer(config)\n",
    "trainer.setup_model()\n",
    "meta_df = trainer.retrieve_transient_metadata(transient_group)\n",
    "train_df, val_df = trainer.split(meta_df, split_frac=0.1)\n",
    "train_srg = srg.filter(train_df.index)\n",
    "val_srg = srg.filter(val_df.index)\n",
    "\n",
    "trainer.train(0, (train_df, train_srg), (val_df, val_srg))\n",
    "trainer.models[0].save(config.model_prefix + \"_full\")\n",
    "\n",
    "# train early-type\n",
    "trainer.config.input_features = [\n",
    "    \"A_ZTF_r\",\n",
    "    \"beta_ZTF_r\",\n",
    "    \"t_0_ZTF_r\",\n",
    "    \"tau_rise_ZTF_r\",\n",
    "    \"extra_sigma_ZTF_r\",\n",
    "    \"A_ZTF_g\",\n",
    "    \"beta_ZTF_g\",\n",
    "    \"t_0_ZTF_g\",\n",
    "    \"tau_rise_ZTF_g\",\n",
    "    \"extra_sigma_ZTF_g\",\n",
    "]\n",
    "\n",
    "trainer.train(1, (train_df, train_srg), (val_df, val_srg))\n",
    "trainer.models[1].save(config.model_prefix + \"_early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus import SuperphotConfig, SuperphotTrainer, SuperphotLightGBM, SuperphotMLP\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "srg = SamplerResultGroup.load(config.sampler_results_fn)\n",
    "\n",
    "trainer = SuperphotTrainer(config)\n",
    "trainer.setup_model()\n",
    "meta_df = trainer.retrieve_transient_metadata(transient_group)\n",
    "\n",
    "# Comment as necessary to get the wanted model.\n",
    "#trainer.models[0] = SuperphotLightGBM.load(config.model_prefix + \"_full.pt\")\n",
    "trainer.models[0] = SuperphotMLP.load(config.model_prefix + \"_full.pt\")\n",
    "#print(trainer.models[0].best_model.feature_name_)\n",
    "#trainer.models[1]= SuperphotLightGBM.load(config.model_prefix + \"_early.pt\")\n",
    "trainer.models[1]= SuperphotMLP.load(config.model_prefix + \"_early.pt\")\n",
    "probs_avg = trainer.evaluate(0, (meta_df, srg))\n",
    "probs_avg.to_csv(config.probs_fn[:-4] + \"_full.csv\")\n",
    "\n",
    "# train early-type\n",
    "trainer.config.input_features = [\n",
    "    \"A_ZTF_r\",\n",
    "    \"beta_ZTF_r\",\n",
    "    \"t_0_ZTF_r\",\n",
    "    \"tau_rise_ZTF_r\",\n",
    "    \"extra_sigma_ZTF_r\",\n",
    "    \"A_ZTF_g\",\n",
    "    \"beta_ZTF_g\",\n",
    "    \"t_0_ZTF_g\",\n",
    "    \"tau_rise_ZTF_g\",\n",
    "    \"extra_sigma_ZTF_g\",\n",
    "]\n",
    "\n",
    "probs_avg_early = trainer.evaluate(1, (meta_df, srg))\n",
    "probs_avg_early.to_csv(config.probs_fn[:-4] + \"_early.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_avg_early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d14d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da9c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superphot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

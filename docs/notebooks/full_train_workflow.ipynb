{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1011fb76-c186-45a1-aaf0-f862cf2a943f",
   "metadata": {},
   "source": [
    "# Full Train Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e576c-1661-4fba-9a2c-f5d7e5311056",
   "metadata": {},
   "source": [
    "Run when you need to train a new classifier from scratch. Will regenerate transient data, refit all samples, and retrain the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d4adc-97f4-4646-b752-e29e7b2d5f03",
   "metadata": {},
   "source": [
    "## Step 0: Update configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b5c23-342c-40f8-912b-67c3a349503e",
   "metadata": {},
   "source": [
    "In the same folder as this notebook, there is a $\\texttt{config.yaml}$ file, which contains all filepaths and configuration options for the training workflow. Please update this now!\n",
    "\n",
    "The most important filepath arguments are:\n",
    "* $\\texttt{create-dirs}$: Probably keep set to True. Create any data subdirectories that are missing.\n",
    "* $\\texttt{data-dir}$: This is where all generated data is stored. Set to the root directory for all outputs.\n",
    "* $\\texttt{relative-dirs}$: If true, all data for each step is stored within subdirectories of data_dir.\n",
    "* $\\texttt{transient-data-fn}$: This is where all transient data is stored as a TransientGroup. Technically a directory but loaded as a single file. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{sampler-results-fn}$: Where light curve fits are stored. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{figs-dir}$: Where all figures are stored (only generated if $\\texttt{plot}$ is set to True). If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "* $\\texttt{models-dir}$: Where all classification models are stored. If relative_dirs is True, is created as a subdirectory of data_dir.\n",
    "\n",
    "The most important sampling and classifier arguments are:\n",
    "* $\\texttt{sampler}$: Set to either dynesty or svi (all lowercase). SVI is faster but forces the posterior into a multivariate Gaussian.\n",
    "* $\\texttt{model-type}$: Set to either LightGBM (recommended) or MLP.\n",
    "* $\\texttt{use-redshift-features}$: If True, includes peak absolute magnitude and redshift as training features.\n",
    "* $\\texttt{fits-per-majority}$: Oversamples such that the majority class has this many samples fed into the classifier. Minority classes will correspond to more input samples per event. Defaults to 5.\n",
    "* $\\texttt{target-label}$: For binary classification - this is the positive label. Set to None for multiclass classification.\n",
    "* $\\texttt{n-folds}$: Number of K-folds. I usually set to 10.\n",
    "* $\\texttt{num-epochs}$: Number of estimators for LightGBM or number of training epochs for MLP.\n",
    "* $\\texttt{n-parallel}$: Number of threads to parallelize data import + sampling over.\n",
    "* $\\texttt{random-seed}$: For reproducibility.\n",
    "\n",
    "If you want to use hierarchical classification with the MLP, you need to also manually fill in the following:\n",
    "* $\\texttt{hierarchy}$: Set to True if you want to use the weighted hierarchical loss function (WHXE). Otherwise, make sure this is set to False.\n",
    "* $\\texttt{class-weights}$: Manually import these values using the class_weights.ipynb notebook to calculate the relevant class weights for the (WHXE). If you are not using this, set it to None.\n",
    "* $\\texttt{graph}$: This is a dictionary of properties of the taxonomic graph. Set each element to null if not using the WHXE.\n",
    "    * $\\texttt{edges}$: A list of 2-element lists containing the edges in the taxonomic graph in use. If not using WHXE, set to None.\n",
    "    * $\\texttt{height}$: The height you want the classifier to go to in terms of the taxonomic tree. Set to None if not using WHXE.\n",
    "    * $\\texttt{root}$: The root node of the tree as a string. This is set to None if not using WHXE.\n",
    "    * $\\texttt{vertices}$: A list of all of the vertices within the tree, including those that are not labels within the dataset. Set to None if not using WHXE. \n",
    "    * $\\texttt{ignored-leaves}$: A list of the leaf vertices within the tree that do not have any counts for them within class_weights or we otherwise want to ignore. Set to None if not using WHXE.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef53e57-bef4-4755-94b1-477a7d6620ec",
   "metadata": {},
   "source": [
    "## Step 1: Generate new TransientSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06baa7f-5374-448d-acdb-8bbc5404a387",
   "metadata": {},
   "source": [
    "Here we will import data from TNS + ALeRCE and generate a new TransientSet, from a list of event names. Names can be from TNS or ZTF.\n",
    "\n",
    "The below code block will retrieve all spectroscopically classified TNS transients. Feel free to change to your own list of names or import script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79328b-94f8-4bd6-8cd7-885799db4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from snapi.query_agents import TNSQueryAgent\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "print(p)\n",
    "#SAVE_DIR = os.path.join(p, \"data\", \"tutorial\") # Use this line if you want to use tutorial data.\n",
    "SAVE_DIR = os.path.join(p, \"data\", \"whxe\")\n",
    "print(SAVE_DIR)\n",
    "\n",
    "tns_agent = TNSQueryAgent(db_path=SAVE_DIR)\n",
    "#tns_agent.update_local_database() # IMPORTANT: run this line if first time using SNAPI or if you want to reimport TNS csv\n",
    "all_names = tns_agent.retrieve_all_names() # only spectroscopically classified\n",
    "all_names = [x for x in all_names if int(x[:4]) > 2018] # because pre-2019 templates are pretty bad\n",
    "print(len(all_names), all_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc3dda-d71f-4da0-9a68-59526d0916ad",
   "metadata": {},
   "source": [
    "The following script will import data for all provided names and generate a TransientGroup object. Will run in parallel across n_cores threads.\n",
    "\n",
    "For the entire TNS dataset (~16000 events), this takes ~30 minutes on 8 parallel cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f0aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First augments the config file to save to your data folder path!\n",
    "# Feel free to change to any path you want\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "config.update(data_dir=SAVE_DIR)\n",
    "config.write_to_file('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f8548-4c29-44aa-b14a-a9b1432e264b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "from superphot_plus.data_generation import import_all_names\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "save_dir = config.transient_data_fn\n",
    "\n",
    "# import data for all_names from query agents \n",
    "# QUALITY CUTS HAPPEN HERE\n",
    "import_all_names(\n",
    "    all_names, save_dir,\n",
    "    checkpoint_freq=512,\n",
    "    n_cores=config.n_parallel,\n",
    "    overwrite=False,\n",
    "    skipped_names_fn = os.path.join(config.data_dir, \"skipped_names.txt\"),\n",
    "    tns_db_path=SAVE_DIR\n",
    ") # set overwrite=False to continue from where left off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332fc7c-1f2f-42ce-a9c2-38c8dbc9db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the TransientGroup we created!\n",
    "from snapi import TransientGroup\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "\n",
    "print(len(transient_group.metadata))\n",
    "print(transient_group.metadata.head())\n",
    "print(transient_group.metadata.groupby('spec_class').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdb3a4d-810c-47df-9a68-9c94070ef085",
   "metadata": {},
   "source": [
    "Finally, before fitting, we want to phase and normalize all the photometry. This is because our samplers expect light curves to already be phased and normalized before fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c6f5c",
   "metadata": {},
   "source": [
    "### STEP 1.5: Hierarchical Counts + Class Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e462753",
   "metadata": {},
   "source": [
    "If we are using WHXE in an MLP, we need generate a taxonomy to be used in our Weighted Hierachical Cross Entropy Loss function.\n",
    "\n",
    "We want to use the counts of items following the quality cuts as that is what our model is training on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bfb94b",
   "metadata": {},
   "source": [
    "##### Substep 1: We want to load in the quality cut data as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "import pandas as pd\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "if config.use_hierarchy:\n",
    "    df = transient_group.metadata\n",
    "    df.to_csv(f'{config.data_dir}/quality_cut_tns_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bb569",
   "metadata": {},
   "source": [
    "##### Substep 2: Adjust Weights, Labels, and Tree\n",
    "\n",
    "Here we need to adjust a few things:\n",
    "\n",
    "1. Update the weight dictionary to be based on the data following the quality cuts in **import_all_names** above. \n",
    "2. Establish we are happy with the adjustment to the tree/taxonomy the user inputted above to desired **height** given in **config.yaml** and develop an updated mapping schema based on the **mapping** schema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e545a4",
   "metadata": {},
   "source": [
    "##### Task 2.1 Update Weight Dictionary\n",
    "\n",
    "If you hadn't originally, go back to the **class_weights.ipynb** file and change the loaded in CSV file into the CSV of the file following quality cuts. Rerun this and update the config.yaml file as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "from superphot_plus.model.taxonomy import Taxonomy\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "if config.use_hierarchy:\n",
    "    \n",
    "    # Copied from output produced in class_weights.ipynb, replace with your own version\n",
    "  new_weights = {'SN Ia': [0.06716554115714546, 5479],\n",
    " 'SN II': [0.3011456628477905, 1222],\n",
    " 'SN IIn': [1.6576576576576576, 222],\n",
    " 'SN Ia-91T-like': [1.8775510204081634, 196],\n",
    " 'SN Ic': [2.5734265734265733, 143],\n",
    " 'SN Ib': [2.852713178294574, 129],\n",
    " 'SLSN-I': [3.5384615384615383, 104],\n",
    " 'SN IIb': [3.5728155339805827, 103],\n",
    " 'SN IIP': [4.088888888888889, 90],\n",
    " 'TDE': [5.041095890410959, 73],\n",
    " 'SN Ic-BL': [5.411764705882353, 68],\n",
    " 'SLSN-II': [7.215686274509804, 51],\n",
    " 'SN Ia-pec': [9.68421052631579, 38],\n",
    " 'SN Ia-91bg-like': [9.945945945945946, 37],\n",
    " 'SN Ibn': [13.62962962962963, 27],\n",
    " 'SN': [14.153846153846153, 26],\n",
    " 'SN Iax[02cx-like]': [15.333333333333334, 24],\n",
    " 'SN Ib/c': [16.727272727272727, 22],\n",
    " 'SN Ia-CSM': [18.4, 20],\n",
    " 'SN Ia-SC': [36.8, 10],\n",
    " 'SN II-pec': [52.57142857142857, 7],\n",
    " 'SN Ib-pec': [73.6, 5]}\n",
    "\n",
    "  config.update(class_weights = new_weights)\n",
    "  config.write_to_file('config.yaml')\n",
    "  print(config.class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52058ac",
   "metadata": {},
   "source": [
    "##### Task 2.2 Adjust the Tree\n",
    "\n",
    "We need to define the taxonomy class variable to be used as our tree for processing as well as adjust the tree (and relevant values) to the desired height. This all happens in the backend when defining **taxonomy**. Thus, you as the user do not see this. For a sanity check, we create a duplicate version below so that you (as the user) can understand what is being used as the taxonomy.\n",
    "\n",
    "If you want to adjust the height, you need to go and change it in the **config.yaml** file now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus.config import SuperphotConfig\n",
    "from superphot_plus.model.taxonomy import Taxonomy\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "if config.use_hierarchy:\n",
    "    taxonomy = Taxonomy(config)\n",
    "    print(taxonomy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_hierarchy:    \n",
    "    taxonomy.draw_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e6217b",
   "metadata": {},
   "source": [
    "##### Task 2.3 Define Needed Attributes\n",
    "\n",
    "For the tree we have defined we need to extract certain features to be used later in the hierarchical loss function. Again, note this is a duplicate and not the actual one used in the backend. This is simply for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_hierarchy:\n",
    "    all_paths, path_lengths, mask_list, y_dict = taxonomy.calc_paths_and_masks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05e95c4-e3aa-4978-8a45-b5e248ea6310",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2 (Option 1): Fit all transients using SVI (faster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2e7f9-a9bd-4c61-80ab-9c88f2252c90",
   "metadata": {},
   "source": [
    "Here, we choose to fit our transients using stochastic variational inference (SVI). If using this option, make sure sampler='superphot_svi' in the config.yaml file. This option is faster but assumes Gaussianity of the posterior space, which can be limiting for certain light curve fits.\n",
    "\n",
    "For all 7202 TNS transients passing quality cuts, this takes ~30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06532f86-feb2-45da-ab33-49966d1f14d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snapi.scripts import fit_transient_group\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "from superphot_plus.samplers.numpyro_sampler import SVISampler\n",
    "from superphot_plus.priors import generate_priors, SuperphotPrior\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "SAVE_DIR = os.path.join(p, \"data\", \"tutorial\")\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "#priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "priors = SuperphotPrior.load(SAVE_DIR + \"/\" + \"global_priors_hier_svi\")\n",
    "svi_sampler = SVISampler(\n",
    "    priors=priors,\n",
    "    num_iter=10_000,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "print(\"Transient group loaded\")\n",
    "\n",
    "result = fit_transient_group(\n",
    "    transient_group,\n",
    "    sampler = svi_sampler,\n",
    "    parallelize=True,\n",
    "    n_parallel=config.n_parallel,\n",
    "    checkpoint_fn = os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    "    checkpoint_freq = 512,\n",
    "    pad=True,\n",
    "    overwrite=True # set to False to continue where left off\n",
    ")\n",
    "SamplerResultGroup(result).save(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9646f8-e84d-4ebb-97e2-9896fbed67a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check plot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import TransientGroup, SamplerResultGroup, Formatter\n",
    "from superphot_plus.samplers.numpyro_sampler import SVISampler\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "svi_sampler = SVISampler(\n",
    "    priors=priors,\n",
    "    num_iter=10_000,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "print(len(sampler_results), sampler_results.metadata.tail())\n",
    "names = sampler_results.metadata.index\n",
    "\n",
    "formatter = Formatter()\n",
    "for n in names[-5:]:\n",
    "    t = transient_group[n] # can index like dictionary\n",
    "    sr = sampler_results[n]\n",
    "    svi_sampler.load_result(sr)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    svi_sampler.plot_fit(\n",
    "        ax,\n",
    "        photometry = t.photometry,\n",
    "        formatter = formatter,\n",
    "    )\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    t.photometry.plot(\n",
    "        ax,\n",
    "        mags=False,\n",
    "        formatter=formatter\n",
    "    )\n",
    "    formatter.make_plot_pretty(ax)\n",
    "    formatter.add_legend(ax)\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4ce7d-b8ad-402f-8d3a-84fc21fb9b85",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2 (Option 2): Fit light curves using dynesty (slower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a2595-fc7d-46ab-bd7f-d2d753e94c3f",
   "metadata": {},
   "source": [
    "Here, we fit our transient photometry using the dynesty nested sampler. This is slower but does not assume Gaussianity of the posterior space, so can better capture degeneracies between parameters. If you use this, make sure to set sampler=superphot_dynesty in the config.yaml file.\n",
    "\n",
    "Runtime for 7202 TNS samples: ~200 minutes (3.5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c3810-fd87-4257-9682-ba600fe2d0b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snapi.scripts import fit_transient_group\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "from superphot_plus.samplers.dynesty_sampler import DynestySampler\n",
    "from superphot_plus.priors import generate_priors, SuperphotPrior\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "p = Path(os.getcwd()).parents[1]\n",
    "SAVE_DIR = os.path.join(p, \"data\", \"tutorial\")\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "#priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "priors = SuperphotPrior.load(SAVE_DIR + \"/\" + \"global_priors_hier_svi\")\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "print(\"Transient group loaded\")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "\n",
    "dynesty_sampler = DynestySampler(\n",
    "    priors=priors,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "result = fit_transient_group(\n",
    "    transient_group,\n",
    "    sampler = dynesty_sampler,\n",
    "    parallelize=True,\n",
    "    n_parallel=config.n_parallel,\n",
    "    checkpoint_fn = os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    "    checkpoint_freq = 128,\n",
    "    pad=False,\n",
    "    overwrite=True, # False to continue from checkpoint\n",
    ")\n",
    "SamplerResultGroup(result).save(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e8afc-964a-4cfd-86e4-818f14eb874a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check plot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import TransientGroup, SamplerResultGroup, Formatter\n",
    "from superphot_plus.samplers.dynesty_sampler import DynestySampler\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "\n",
    "svi_sampler = DynestySampler(\n",
    "    priors=priors,\n",
    "    random_state=config.random_seed,\n",
    ")\n",
    "\n",
    "names = sampler_results.metadata.index\n",
    "\n",
    "formatter = Formatter()\n",
    "for n in names[-5:]: # neweet \n",
    "    t = transient_group[n] # can index like dictionary\n",
    "    sr = sampler_results[n]\n",
    "    svi_sampler.load_result(sr)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    svi_sampler.plot_fit(\n",
    "        ax,\n",
    "        photometry = t.photometry,\n",
    "        formatter = formatter,\n",
    "    )\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    t.photometry.plot(\n",
    "        ax,\n",
    "        mags=False,\n",
    "        formatter=formatter\n",
    "    )\n",
    "    formatter.make_plot_pretty(ax)\n",
    "    formatter.add_legend(ax)\n",
    "\n",
    "    formatter.reset_colors()\n",
    "    formatter.reset_markers()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3bf32-e38c-4bf9-874f-c77a9bd19610",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2.5: Convert SamplerResultGroup posteriors back to uncorrelated Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c543bc2-98a5-403f-9bde-d487bb9d02cf",
   "metadata": {},
   "source": [
    "When sampling, the posteriors are saved as the inputs to our flux model. The Gaussian priors, however, were converted to log-Gaussians and multiplied by base parameters where necessary before being fed into the model function. Therefore, we must revert these log-Gaussian and relative parameters back to their original uncorrelated Gaussian draws before using as classifier inputs. We do this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dacf611-9d09-4e09-9999-95c5975675e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: only run once!\n",
    "import os\n",
    "from snapi import SamplerResultGroup\n",
    "from superphot_plus.priors import generate_priors\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "priors = generate_priors([\"ZTF_r\",\"ZTF_g\"])\n",
    "sampler_results = SamplerResultGroup.load(\n",
    "    os.path.join(\n",
    "        config.data_dir,\n",
    "        \"tmp_sampler_results\"\n",
    "    )\n",
    ")\n",
    "\n",
    "new_sr = []\n",
    "for i, sr in enumerate(sampler_results):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Converted {i} out of {len(sampler_results)} fits\")\n",
    "    sr.fit_parameters = priors.reverse_transform(sr.fit_parameters)\n",
    "    new_sr.append(sr)\n",
    "    \n",
    "new_sampler_results = SamplerResultGroup(new_sr)\n",
    "new_sampler_results.save(config.sampler_results_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi import SamplerResultGroup\n",
    "from superphot_plus.config import SuperphotConfig\n",
    "import os\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "srg = SamplerResultGroup.load(config.sampler_results_fn)\n",
    "metadata = srg.metadata\n",
    "metadata.to_csv(os.path.join(config.data_dir, \"all_samples.csv\"))\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6128b82d-9162-47c1-adf9-4fe3a65a305b",
   "metadata": {},
   "source": [
    "## Step 3: Train + evaluate classifier from sampling posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb48bb5-24ed-4017-8b29-fca16da4e049",
   "metadata": {},
   "source": [
    "Here we train a classifier with our uncorrelated posterior features. This script will automatically split the data into K-folds, oversample the training and validation sets to even out minority classes, and train either LightGBMs (recommended) or MLPs. If plot is True, metric plots and confusion matrices will also be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076c371-e919-4dc8-807c-b2aa585776dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus import SuperphotConfig, SuperphotTrainer\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "# remove A_ZTF_r and t_0_ZTF_r from params used in classification - see paper for details\n",
    "metadata = pd.read_csv(os.path.join(config.data_dir, \"all_samples.csv\"), index_col = 0)\n",
    "keep_cols = metadata.drop(\n",
    "    columns=['A_ZTF_r_median', 't_0_ZTF_r_median', 'score_median', 'sampler']\n",
    ").columns\n",
    "config.input_features = [c.replace(\"_median\", \"\") for c in keep_cols]\n",
    "print(config.input_features)\n",
    "\n",
    "# train classifier\n",
    "trainer = SuperphotTrainer(config)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90d6f4",
   "metadata": {},
   "source": [
    "Finally, we train a version of the classifier without a test set (aka we use the entire dataset in training or validation). This is what we'll be using to classify a new, disparate dataset.\n",
    "\n",
    "In addition to the classic full-phase classifier, we train a classifier that only uses early-phase features (excludes plateau durations and fall timescales). This is more effective at classifying partial supernova light curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc790c91-898a-4e3f-b94c-c96377e448af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'fx' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msuperphot_plus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SuperphotConfig, SuperphotTrainer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msnapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransientGroup, SamplerResultGroup\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Summer2025/superphotplus/superphot-plus/src/superphot_plus/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from .data_generation import import_all_names\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SuperphotLightGBM, SuperphotMLP, ModelMetrics\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpriors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m generate_priors\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#from .samplers import DynestySampler, SVISampler, NUTSSampler\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Summer2025/superphotplus/superphot-plus/src/superphot_plus/model/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SuperphotLightGBM\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SuperphotMLP\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelMetrics\n",
      "File \u001b[0;32m~/Desktop/Summer2025/superphotplus/superphot-plus/src/superphot_plus/model/lightgbm.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EPOCHS\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelMetrics\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SuperphotClassifier\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSuperphotLightGBM\u001b[39;00m(SuperphotClassifier):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The LightGBM model.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m        The MLP architecture configuration.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Summer2025/superphotplus/superphot-plus/src/superphot_plus/model/classifier.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightgbm\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_num_threads(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_num_interop_threads(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/superphot/lib/python3.10/site-packages/torch/__init__.py:2600\u001b[0m\n\u001b[1;32m   2596\u001b[0m     torch_module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;18m__name__\u001b[39m, device_type])\n\u001b[1;32m   2597\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules[torch_module_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m-> 2600\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   2601\u001b[0m     export \u001b[38;5;28;01mas\u001b[39;00m export,\n\u001b[1;32m   2602\u001b[0m     func \u001b[38;5;28;01mas\u001b[39;00m func,\n\u001b[1;32m   2603\u001b[0m     library \u001b[38;5;28;01mas\u001b[39;00m library,\n\u001b[1;32m   2604\u001b[0m     return_types \u001b[38;5;28;01mas\u001b[39;00m return_types,\n\u001b[1;32m   2605\u001b[0m )\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cond \u001b[38;5;28;01mas\u001b[39;00m cond, while_loop \u001b[38;5;28;01mas\u001b[39;00m while_loop\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n",
      "File \u001b[0;32m/opt/miniconda3/envs/superphot/lib/python3.10/site-packages/torch/func/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m grad, grad_and_value, vmap\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_norm_replacement\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m replace_all_batch_norm_modules_\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager_transforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     debug_unwrap,\n\u001b[1;32m      5\u001b[0m     functionalize,\n\u001b[1;32m      6\u001b[0m     hessian,\n\u001b[1;32m      7\u001b[0m     jacfwd,\n\u001b[1;32m      8\u001b[0m     jacrev,\n\u001b[1;32m      9\u001b[0m     jvp,\n\u001b[1;32m     10\u001b[0m     linearize,\n\u001b[1;32m     11\u001b[0m     vjp,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_call\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional_call, stack_module_state\n\u001b[1;32m     16\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_and_value\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug_unwrap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     31\u001b[0m ]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/superphot/lib/python3.10/site-packages/torch/_functorch/eager_transforms.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m argnums_t, exposed_in\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionalTensor\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m const_fold\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproxy_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_fx\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pytree \u001b[38;5;28;01mas\u001b[39;00m pytree\n",
      "File \u001b[0;32m/opt/miniconda3/envs/superphot/lib/python3.10/site-packages/torch/fx/experimental/const_fold.py:17\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msplit_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m split_module\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFoldedGraphModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_unique_attr_name_in_module\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_const_subgraphs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m ]\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mFoldedGraphModule\u001b[39;00m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfx\u001b[49m\u001b[38;5;241m.\u001b[39mGraphModule):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    FoldedGraphModule is a GraphModule which also contains another\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    `const_subgraph_module` representing a subgraph which has all const attr\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    on which attrs.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     29\u001b[0m         root: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m         device_for_folded_attrs: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     ):\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch' has no attribute 'fx' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from superphot_plus import SuperphotConfig, SuperphotTrainer\n",
    "from snapi import TransientGroup, SamplerResultGroup\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "# remove A_ZTF_r and t_0_ZTF_r from params used in classification - see paper for details\n",
    "metadata = pd.read_csv(os.path.join(config.data_dir, \"all_samples.csv\"), index_col = 0)\n",
    "keep_cols = metadata.drop(\n",
    "    columns=['A_ZTF_r_median', 't_0_ZTF_r_median', 'score_median', 'sampler']\n",
    ").columns\n",
    "config.input_features = [c.replace(\"_median\", \"\") for c in keep_cols]\n",
    "print(config.input_features)\n",
    "\n",
    "transient_group = TransientGroup.load(config.transient_data_fn)\n",
    "srg = SamplerResultGroup.load(config.sampler_results_fn)\n",
    "\n",
    "trainer = SuperphotTrainer(config)\n",
    "trainer.setup_model()\n",
    "meta_df = trainer.retrieve_transient_metadata(transient_group)\n",
    "train_df, val_df = trainer.split(meta_df, split_frac=0.1)\n",
    "train_srg = srg.filter(train_df.index)\n",
    "val_srg = srg.filter(val_df.index)\n",
    "\n",
    "trainer.train(0, (train_df, train_srg), (val_df, val_srg))\n",
    "trainer.models[0].save(config.model_prefix + \"_full\")\n",
    "print(trainer.models[0].best_model.feature_name_)\n",
    "\n",
    "# Calls to trainer.evaluate -> mlp.evaluate -> mlp.get_predictions ->\n",
    "probs_avg = trainer.evaluate(0, (meta_df, srg))\n",
    "probs_avg.to_csv(config.probs_fn[:-4] + \"_full.csv\")\n",
    "\n",
    "# # train early-type\n",
    "# metadata = pd.read_csv(os.path.join(config.data_dir, \"all_samples.csv\"), index_col = 0)\n",
    "# keep_cols = metadata.drop(\n",
    "#     columns=['A_ZTF_r_median', 't_0_ZTF_r_median', 'score_median', 'sampler']\n",
    "# ).columns\n",
    "# trainer.config.input_features = [c.replace(\"_median\", \"\") for c in keep_cols if (\n",
    "#         ('tau_fall' not in c) and ('gamma' not in c)\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# trainer.train(1, (train_df, train_srg), (val_df, val_srg))\n",
    "# trainer.models[1].save(config.model_prefix + \"_early\")\n",
    "# print(trainer.models[1].best_model.feature_name_)\n",
    "\n",
    "# probs_avg = trainer.evaluate(1, (meta_df, srg))\n",
    "# probs_avg.to_csv(config.probs_fn[:-4] + \"_early.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842b988",
   "metadata": {},
   "source": [
    "Below we plot the confusion matrices for both the full and early models. These plots can be found in the same folder where you saved all the data for this training run under **figs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superphot_plus.plotting.confusion_matrices import *\n",
    "from superphot_plus import SuperphotConfig\n",
    "import pandas as pd\n",
    "\n",
    "config = SuperphotConfig.from_file(\"config.yaml\")\n",
    "\n",
    "def df_from_csv(filepath):\n",
    "    \"\"\"\n",
    "    Loads a CSV file into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The resulting DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{filepath}'\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: File at '{filepath}' is empty or improperly formatted\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "#early_df = df_from_csv(\"/Users/charisgraham/Desktop/Summer2025/superphotplus/superphot-plus/data/whxe/probabilities/probs_superphot_svi_MLP_None_False_10_None_5_1_42_64_3_0.001_64_early.csv\")\n",
    "full_df = df_from_csv(f\"{config.probs_fn[:-4]}_full.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f523d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrices(config, full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f694ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrices(config, early_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a312dbd",
   "metadata": {},
   "source": [
    "# Cut out outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089aefe1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superphot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
